{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38600144",
   "metadata": {},
   "source": [
    "# Implementing Logistic Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f05231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2307e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iter=1000):\n",
    "        # Initialize class attributes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        # Sigmoid function to map to values between 0 and 1\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Getting the number of rows and columns of X\n",
    "        n_rows, n_cols = X.shape\n",
    "\n",
    "        # Initialize weights with random values between 0 and 1\n",
    "        self.W = np.random.rand(n_cols)\n",
    "\n",
    "        # Initialize the bias with a random value between 0 and 1\n",
    "        self.b = np.random.rand()\n",
    "\n",
    "        # Iterating a number n_iter of times\n",
    "        for i in range(self.n_iter):\n",
    "            # Calculate the output y\n",
    "            y = np.dot(X, self.W) + self.b\n",
    "\n",
    "            # Apply the sigmoid function to obtain the probabilities\n",
    "            probs = self._sigmoid(y)\n",
    "\n",
    "            # Calculate the gradient of weights and bias\n",
    "            dW = np.dot(X.T, (probs - y)) / n_rows\n",
    "            db = np.sum(probs - y) / n_rows\n",
    "\n",
    "            # Update the weights using gradient descent\n",
    "            self.W -= self.learning_rate * dW\n",
    "\n",
    "            # Update the bias using gradient descent\n",
    "            self.b -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calculate the output y\n",
    "        y = np.dot(X, self.W) + self.b\n",
    "\n",
    "        # Apply the sigmoid function to obtain the probabilities\n",
    "        probs = self._sigmoid(y)\n",
    "\n",
    "        # Generate binary predictions based on the probabilities\n",
    "        y_pred = np.where(probs >= 0.5, 1, 0)\n",
    "\n",
    "        # Return y_pred\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87afc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "maintenance_data = pd.read_csv('predictive_maintenance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa65752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping ID columns\n",
    "maintenance_data.drop(columns = ['UDI', 'Product ID'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59763ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping type column to numbers\n",
    "maintenance_data['Type'] = np.where(maintenance_data['Type'] == 'L', \n",
    "                                    0, \n",
    "                                   np.where(maintenance_data['Type'] == 'M',\n",
    "                                           1,\n",
    "                                           2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a48541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancing LogisticRegression class\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5143ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating input and output variable\n",
    "X = maintenance_data.drop(columns = ['Target', 'Failure Type'])\n",
    "y = maintenance_data['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a908f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f06708e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e2ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fb9213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
